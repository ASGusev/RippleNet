{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiData PDF loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы взяли все сущности, которые являются `musical group` ([Q215380](https://www.wikidata.org/wiki/Q215380)) (либо каким-то их подклассом), а также всех людей, у которых в графе `occupation` указано `singer` ([Q177220](https://www.wikidata.org/wiki/Q177220))\n",
    "\n",
    "В итоге получилось собрать данные для 76104 групп и 87430 певцов.\n",
    "В рамках этой работы они все будут считаться исполнителями.\n",
    "\n",
    "Для каждого автора мы собрали следующую информацию: название на английском языке, список характерных жанров ([P136](https://www.wikidata.org/wiki/Property:P136)), страна происхождения ([P495](https://www.wikidata.org/wiki/Property:P495)), источники вдохновения ([P737](https://www.wikidata.org/wiki/Property:P737)), список наград ([P166](https://www.wikidata.org/wiki/Property:P166)). Название использовалось для сопоставления исполнителей с данными датасета Last.fm, а остальные связи (588521 отношений) использовались для построения графа знаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = dict()\n",
    "authors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(p, relations, authors):\n",
    "    with open(p, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data:\n",
    "        if not item['label']:\n",
    "            continue\n",
    "        authors[item['label']] = item['item']\n",
    "        datas[item['label']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_data('wikidata/strange_groups.json', datas, authors)\n",
    "parse_data('wikidata/groups_0.json', datas, authors)\n",
    "parse_data('wikidata/groups_1.json', datas, authors)\n",
    "parse_data('wikidata/singers_0.json', datas, authors)\n",
    "parse_data('wikidata/singers_1.json', datas, authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Last.fm dataset\n",
    "Оригинальная статья: [The LFM-1b Dataset for Music Retrieval and Recommendation](https://www.jku.at/fileadmin/gruppen/173/Research/schedl_icmr_2016.pdf)\n",
    "\n",
    "Сам датасет можно найти [здесь](http://www.cp.jku.at/datasets/LFM-1b/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из 1 088 161 692 прослушиваний пользователями треков с Last.fm. \n",
    "\n",
    "Количество пользователей:    120 323\n",
    "\n",
    "Количество треков:        32 291 134\n",
    "\n",
    "Количество альбомов:      15 991 038\n",
    "\n",
    "Количество исполнителей:   3 190 371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2wd = {}\n",
    "\n",
    "with open('LFM-1b/LFM-1b_artists.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        artist_id, name = parts\n",
    "        if name in authors:\n",
    "            artist2wd[int(artist_id)] = authors[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для 91001 исполнителей удалось найти соответствие сущностей из wikidata и id-шниками из датасета Last.fm\n"
     ]
    }
   ],
   "source": [
    "print(f'Для {len(artist2wd)} исполнителей удалось найти соответствие сущностей из wikidata и id-шниками из датасета Last.fm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cnt = Counter()\n",
    "artist_cnt = Counter()\n",
    "song_cnt = Counter()\n",
    "interactions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LFM-1b/LFM-1b_LEs.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if random.random() > 0.00125:\n",
    "            continue\n",
    "        \n",
    "        parts = line.strip().split('\\t')\n",
    "        \n",
    "        user_id = int(parts[0])\n",
    "        artist_id = int(parts[1])\n",
    "        albom_id = int(parts[2])\n",
    "        song_id = int(parts[3])\n",
    "        \n",
    "        if artist_id not in artist2wd:\n",
    "            continue\n",
    "        \n",
    "        interactions.append((user_id, artist_id, albom_id, song_id))\n",
    "        \n",
    "        user_cnt[user_id] += 1\n",
    "        artist_cnt[artist_id] += 1\n",
    "        song_cnt[song_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = list([(user_id, artist_id, albom_id, song_id) for user_id, artist_id, albom_id, song_id in set(interactions) \n",
    "                     if user_cnt[user_id] > 5 and song_cnt[song_id] > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185089"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставили в датасете только сматчившихся с wikidata исполнителей, выбрали случайно 0.125% примеров и удалили пользователей и песни со слишким маленьким числом взаимодействий. В итоге имеем выборку из 4 156 987 прослушываний.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "song2albom = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lastfm/events.csv', 'w', encoding='utf-8') as events_f, \\\n",
    "        open('lastfm/item_index2entity_id_rehashed.txt', 'w', encoding='utf-8') as mappings_f:\n",
    "    for user_id, artist_id, albom_id, song_id in interactions:\n",
    "        print(f'{user_id}\\t{song_id}\\t1', file=events_f)\n",
    "        song_str = f'song#{song_id}'\n",
    "        if song_str not in graph_dict:\n",
    "            graph_dict[song_str] = len(graph_dict)\n",
    "            print(f'{song_id}\\t{graph_dict[song_str]}', file=mappings_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id, artist_id, albom_id, song_id in interactions:\n",
    "    if artist2wd[artist_id] not in graph_dict:\n",
    "        graph_dict[artist2wd[artist_id]] = len(graph_dict)\n",
    "    if f'albom#{albom_id}' not in graph_dict:\n",
    "        graph_dict[f'albom#{albom_id}'] = len(graph_dict)\n",
    "        \n",
    "    relations.add((\n",
    "        graph_dict[f'song#{song_id}'],\n",
    "        'authorship',\n",
    "        graph_dict[artist2wd[artist_id]]\n",
    "    ))\n",
    "    relations.add((\n",
    "        graph_dict[artist2wd[artist_id]],\n",
    "        'authorship_reversed',\n",
    "        graph_dict[f'song#{song_id}']\n",
    "    ))\n",
    "    \n",
    "    relations.add((\n",
    "        graph_dict[f'song#{song_id}'],\n",
    "        'part_of',\n",
    "        graph_dict[f'albom#{albom_id}']\n",
    "    ))\n",
    "    relations.add((\n",
    "        graph_dict[f'albom#{albom_id}'],\n",
    "        'contains',\n",
    "        graph_dict[f'song#{song_id}']\n",
    "    ))\n",
    "    \n",
    "    relations.add((\n",
    "        graph_dict[f'albom#{albom_id}'],\n",
    "        'authorship',\n",
    "        graph_dict[artist2wd[artist_id]]\n",
    "    ))\n",
    "    relations.add((\n",
    "        graph_dict[artist2wd[artist_id]],\n",
    "        'authorship_reversed',\n",
    "        graph_dict[f'albom#{albom_id}']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist_id, data in datas.items():\n",
    "    if data['item'] not in graph_dict:\n",
    "        continue\n",
    "    if 'country' in data and data['country']:\n",
    "        if data['country'] not in graph_dict:\n",
    "            graph_dict[data['country']] = len(graph_dict)\n",
    "        relations.add((\n",
    "            graph_dict[data['item']],\n",
    "            'originalCountry',\n",
    "            graph_dict[data['country']]\n",
    "        ))\n",
    "        relations.add((\n",
    "            graph_dict[data['country']],\n",
    "            'countryOf',\n",
    "            graph_dict[data['item']]\n",
    "        ))\n",
    "    for genre in data['genres'].strip().split('|'):\n",
    "        if genre not in graph_dict:\n",
    "            graph_dict[genre] = len(graph_dict)\n",
    "        relations.add((\n",
    "            graph_dict[data['item']],\n",
    "            'genre',\n",
    "            graph_dict[genre]\n",
    "        ))\n",
    "        relations.add((\n",
    "            graph_dict[genre],\n",
    "            'genreOf',\n",
    "            graph_dict[data['item']]\n",
    "        ))\n",
    "    for influenser in data['influensers'].strip().split('|'):\n",
    "        if influenser not in graph_dict:\n",
    "            graph_dict[influenser] = len(graph_dict)\n",
    "        relations.add((\n",
    "            graph_dict[data['item']],\n",
    "            'influensedBy',\n",
    "            graph_dict[influenser]\n",
    "        ))\n",
    "        relations.add((\n",
    "            graph_dict[influenser],\n",
    "            'influenseTo',\n",
    "            graph_dict[data['item']]\n",
    "        ))\n",
    "    for award in data['awards'].strip().split('|'):\n",
    "        if award not in graph_dict:\n",
    "            graph_dict[award] = len(graph_dict)\n",
    "        relations.add((\n",
    "            graph_dict[data['item']],\n",
    "            'awardedBy',\n",
    "            graph_dict[award]\n",
    "        ))  \n",
    "        relations.add((\n",
    "            graph_dict[award],\n",
    "            'awardedTo',\n",
    "            graph_dict[data['item']]\n",
    "        ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177120"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lastfm/kg_rehashed.txt', 'w', encoding='utf-8') as f:\n",
    "    for a, relation, b in relations:\n",
    "        print(f'{a}\\t{relation}\\t{b}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Defaul Python",
   "language": "python",
   "name": "default-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
